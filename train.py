import sysimport numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom sklearn import linear_modelfrom xgboost import XGBClassifierfrom sklearn.svm import SVCfrom itertools import productimport warningsfrom data_preprocessing import data_preprocessingfrom plot_histogram import plot_histogramfrom split_dataset import split_datasetclass cancerPrediction():    def __init__(self, clfName : str, props : np.array, *data):        self.clfHash = {            "lr": linear_model.LogisticRegression(max_iter = 2000, multi_class = 'multinomial'),            "xgb": XGBClassifier(n_estimators = 300),            "svm": SVC(kernel = "linear")        }                self.clfName = clfName        self.clf = self.clfHash[clfName]        self.props = props        (self.X_train, self.X_valid, self.X_test,         self.y_train, self.y_valid, self.y_test) = data        self.best_mse_acc = (10000, 0)        self.best_clf = None            def set_params(self, **params):        self.clf.set_params(**params)    def MSE(self, predictions, labels):        differences = [(x-y)**2 for x,y in zip(predictions, labels)]        return sum(differences) / len(differences)        def accuracy(self, preds, labels):        return (preds == labels).sum().astype(float) / len(preds) * 100        def train(self, **paramsCV):        self.keys, self.vals = paramsCV.keys(), paramsCV.values()        for params in product(*self.vals):            self.set_params(**dict(zip(self.keys, params)))            self.clf.fit(self.X_train, self.y_train)            y_pred = self.clf.predict(self.X_valid)            mse, acc = self.MSE(y_pred, self.y_valid), self.accuracy(y_pred, self.y_valid)                        if acc > self.best_mse_acc[1] and mse < self.best_mse_acc[0]:                self.best_mse_acc = (mse, acc)                self.best_clf = self.clf                        y_test_pred = self.best_clf.predict(self.X_test)        y_valid_pred = self.best_clf.predict(self.X_valid)                mse_test, acc_test = self.MSE(y_test_pred, self.y_test), self.accuracy(y_test_pred, self.y_test)        mse_valid, acc_valid = self.MSE(y_valid_pred, self.y_valid), self.accuracy(y_valid_pred, self.y_valid)            print("Best {} model".format(self.clfName))        for _, (k, v) in enumerate(self.best_clf.get_params().items()):            if k in self.keys:                print("\t{} = {}".format(k, v))                        print("\nMSE for valid = {}".format(mse_valid))        print("ACC for valid = {}".format(acc_valid))        print("\nMSE for test  = {}".format(mse_test))        print("ACC for test  = {}\n".format(acc_test))            def plot_weights(self):        coefs = pd.DataFrame(           self.best_clf.coef_.T,           columns = ['Level low', 'Level medium', 'Level high'], index = self.props        )                coefs.plot(kind='barh', figsize=(10, 12))        clfFullname = "Logistic Regression" if self.clfName == "lr" else "SVM"        plt.title('Coefficients of {} model'.format(clfFullname))        plt.axvline(x = 0, color = '.5')        plt.subplots_adjust(left = .3)        plt.savefig(f'img/weights_{self.clfName}.png', bbox_inches = 'tight')        # plt.show()        def plot_feature_importance(self):        coefs = pd.DataFrame(           self.best_clf.feature_importances_,           columns = ['Feature Importance'], index = self.props        )                coefs.plot(kind='barh', figsize=(10, 12))        plt.title('Feature importance of XGBoost model')        plt.axvline(x = 0, color = '.5')        plt.subplots_adjust(left = .3)        plt.savefig(f'img/weights_{self.clfName}.png', bbox_inches = 'tight')        # plt.show()            def plot(self):        if self.clfName == "xgb":            self.plot_feature_importance()        else:            self.plot_weights()        if __name__ == "__main__":    warnings.filterwarnings('ignore')        model_params_CV = {        "lr" : {            "solver": ['newton-cg', 'sag', 'saga', 'lbfgs'],            "C": np.arange(0.01, 0.11, 0.002),        },        "xgb" : {            "learning_rate": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],            "max_depth": range(1, 7),        },        "svm": {}    }        df = data_preprocessing("cancer patient data sets.csv", drop = ["Patient Id","index"])    props = plot_histogram(df)    data = split_dataset(df, "Level", {'Low': 0, 'Medium': 1, "High" : 2}, 0.3)        if len(sys.argv) > 1:        modelName = sys.argv[1]        model = cancerPrediction(modelName, props, *data)        model.train(**model_params_CV[modelName])        model.plot()    else:        for modelName in model_params_CV:            model = cancerPrediction(modelName, props, *data)            model.train(**model_params_CV[modelName])            model.plot()        